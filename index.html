<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous">

    <!-- Academicons (e.g., CV icon, doi icon) -->
    <!-- Had issues with these displaying when loading via the internet, so I 
      downloaded the relevant CSS files and am now storing them locally for 
      better reliability.
    -->
    <link rel="stylesheet" href="css/academicons.min.css">

    <!-- Fontawesome  icons -->
    <script src="https://kit.fontawesome.com/e3a7fcb65d.js" crossorigin="anonymous"></script>
    
    <!-- Other style settings -->
    <style> 
      ul.loose li:first-child { margin-top: 0px; }
      ul.loose li { margin-top: 10px; }
      ul.horizontal {
        list-style-type:none; 
        padding-left:10px;
      }
      ul.horizontal li {display: inline-block; margin-right:20px; margin-top:0px}
    </style>
  
    <!-- Title of my website -->
    <title>Osman Asif Malik</title>
  </head>
  
  <body>
    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous"></script>
    
    <!-- START OF WEBSITE CONTENT -->
    <div class="container-fluid">

      <!-- Picture, contact info and links -->
      <div class="row d-flex justify-content-center" style="margin-top:40px;">
        <div class="col-md-2" style="display:block">
          <img src="photo.jpg" style="max-width:100%;max-height:100%;">
        </div>
        <div class="col-md-6" style="display:block;">
          <h1>
            Osman Asif Malik
          </h1>
          <p>
            Research Scientist<br>
            Encube Technologies
          </p>
          <p>
          <ul style="list-style-type:none; padding-left:0">
            <li><i class="far fa-envelope"></i> osman (dot) malik (at) colorado (dot) edu</li>
            <li><i class="fab fa-github"></i> <a href="https://github.com/OsmanMalik">GitHub</a></li>
            <li><i class="ai ai-google-scholar ai-1x"></i> <a href="https://scholar.google.com/citations?user=WAleKq0AAAAJ&hl=en&oi=ao">Google Scholar</a></li>
            <li><i class="fab fa-linkedin-in"></i> <a href="https://www.linkedin.com/in/osmanm">LinkedIn</a></li>
            <li><i class="ai ai-orcid ai-1x"></i> <a href="https://orcid.org/0000-0003-4477-481X">ORCID</a></li>
            <li><i class="ai ai-cv ai-1x"></i> <a href="cv.pdf">Curriculum Vitae</a></li>
          </ul>
          </p>
        </div>
      </div>

      <!-- About me -->
      <div class="row d-flex justify-content-center" style="margin-top:20px">
        <div class="col-md-8">
          <p>
            I work as a research scientist at <a href="https://www.getencube.com/">Encube Technologies</a>. 
            Prior to this, I was an <a href="https://crd.lbl.gov/news-and-publications/news/2021/new-alvarez-fellow-eyes-new-applications-for-math-and-ml/">Alvarez Postdoctoral Fellow</a> at Lawrence Berkeley National Laboratory where I was a member of the <a href="https://crd.lbl.gov/divisions/amcr/applied-mathematics-dept/scalable-solvers/">Scalable Solvers Group</a>. 
            I received my PhD in Applied Mathematics from University of Colorado Boulder where I was advised by <a href="https://amath.colorado.edu/faculty/becker/">Stephen Becker</a>.
            During my PhD, I had the opportunity to do internships at <a href="https://www.research.ibm.com/">IBM Research</a> in Yorktown Heights, NY, and at <a href="https://www.fujitsu.com/us/about/businesspolicy/tech/rd/">Fujitsu Research of America</a> (formerly known as Fujitsu Laboratories of America) in Sunnyvale, CA.
          </p>

          <p>
            <b>To get in touch:</b> 
            Please either send me an email to my old university email (see above), or reach out on LinkedIn.
          </p>

          <p>
            My research interests include
            <ul>
              <li>Machine learning</li>
              <li>Randomized algorithms</li> 
              <li>Numerical linear algebra</li>
              <li>Tensor decomposition</li>
              <li>Optimization</li>
              <li>Quantum computing</li>
            </ul>
          </p>

          <p>
            Recordings of some talks I've given:
            <ul>
              <li><a href="https://vimeo.com/919760058">Fast Algorithms for Constructing Surrogate Models</a>. Berkeley Lab Postdoc Symposium, Berkeley, CA. February 6, 2024.</li></li> 
              <li><a href="https://www.youtube.com/watch?v=j7qSlahlHRk">Sampling-Based Decomposition Algorithms for Arbitrary Tensor Networks</a>. Mila's Tensor Network Reading Group, held virtually. January 30, 2024.</li>
              <li><a href="https://www.youtube.com/watch?v=mlbBuOdJPL0">Structured Sketching and Tensor Decomposition</a>. Workshop on Sparse Tensor Computations, Chicago, IL. October 19, 2023.</li>
              <li><a href="https://slideslive.com/38984000">More Efficient Sampling for Tensor Decomposition With Worst-Case Guarantees</a>. International Conference on Machine Learning (ICML), Baltimore, MD. July 21, 2022.</li>
              <li><a href="https://www.youtube.com/watch?v=eUovP1rbL3g">Faster Algorithms for Tensor Ring Decomposition</a>. Berkeley Lab Postdoc Symposium, held virtually. February 8, 2022.</li>
              <li><a href="https://icml.cc/virtual/2021/poster/8447">A Sampling-Based Method for Tensor Ring Decomposition</a>. International Conference on Machine Learning (ICML), held virtually. July 22, 2021.</li>
              <!-- 
                <li><a href=""></a></li> 
              -->
            </ul> 
          </p>
        </div>
      </div>



      <!-- Publications -->
      <div class="row d-flex justify-content-center" style="margin-top:20px">
        <div class="col-md-8">
          <h2>
            Publications
          </h2>
          
          <h5>
            Preprint Papers
          </h5>
          <ul class="loose">

            <li>
              Y. Yaniv, <u>O. A. Malik</u>, P. Ghysels, X. S. Li.
              <i>Construction of hierarchically semi-separable matrix representation using adaptive Johnson-Lindenstrauss sketching</i>.
              arXiv:2302.01977, 2023.
              <ul class="horizontal"> 
                <li><i class="ai ai-arxiv ai-1x"></i> <a href="https://arxiv.org/abs/2302.01977">Preprint</a></li>
                <li><i class="fab fa-github"></i> <a href="https://github.com/pghysels/STRUMPACK/">Code</a></li>
              </ul>
            </li>

            <li>
              <u>O. A. Malik</u>, V. Bharadwaj, R. Murray.
              <i>Sampling-based decomposition algorithms for arbitrary tensor networks</i>.
              arXiv:2210.03828, 2022.
              <ul class="horizontal"> 
                <li><i class="ai ai-arxiv ai-1x"></i> <a href="https://arxiv.org/abs/2210.03828">Preprint</a></li>
                <li><i class="fab fa-github"></i> <a href="https://github.com/OsmanMalik/TNS">Code</a></li>
              </ul>
            </li>

            <li>
              <u>O. A. Malik</u>, Y. Xu, N. Cheng, S. Becker, A. Doostan, A. Narayan.
              <i>Fast algorithms for monotone lower subsets of Kronecker least squares problems</i>.
              arXiv:2209.05662, 2022.
              <ul class="horizontal"> 
                <li><i class="ai ai-arxiv ai-1x"></i> <a href="https://arxiv.org/abs/2209.05662">Preprint</a></li>
                <li><i class="fab fa-github"></i> <a href="https://github.com/CU-UQ/monotone-lower-set">Code</a></li>
              </ul>
            </li>          

          </ul>

        
          <h5>
            Journal and Conference Papers
          </h5>
          <ul class="loose">

            <li>
              V. Bharadwaj, B. T. Rakhshan, <u>O. A. Malik</u>, G. Rabusseau.
              <i>Efficient leverage score sampling for tensor train decomposition</i>.
              To appear at <b>Advances in Neural Information Processing Systems (NeurIPS)</b>, 2024, arXiv:2406.02749.
              <ul class="horizontal"> 
                <li><i class="ai ai-arxiv ai-1x"></i> <a href="https://arxiv.org/abs/2406.02749">Preprint</a></li>
              </ul>
            </li>

            <li>
              V. Bharadwaj, <u>O. A. Malik</u>, R. Murray, A. Bulu√ß, J. Demmel.
              <i>Distributed-memory randomized algorithms for sparse tensor CP decomposition</i>.
              <b>ACM Symposium on Parallelism in Algorithms and Architectures (SPAA)</b>, pp. 155-168, 2024.
              <ul class="horizontal"> 
                <li><i class="fas fa-file-alt"></i> <a href="https://doi.org/10.1145/3626183.3659980">Paper</a></li>
                <li><i class="ai ai-arxiv ai-1x"></i> <a href="https://arxiv.org/abs/2210.05105">Preprint</a></li>
                <li><i class="fab fa-github"></i> <a href="https://github.com/vbharadwaj-bk/rdist_tensor">Code</a></li>
              </ul>
            </li>

            <li>
              N. Cheng, <u>O. A. Malik</u>, Y. Xu, S. Becker, A. Doostan, A. Narayan.
              <i>Subsampling of parametric models with bifidelity boosting</i>.
              <b>SIAM/ASA Journal on Uncertainty Quantification</b> 12, issue 2, pp. 213-241, 2024.
              <ul class="horizontal"> 
                <li><i class="fas fa-file-alt"></i> <a href="https://doi.org/10.1137/22M1524989">Paper</a></li>
                <li><i class="ai ai-arxiv ai-1x"></i> <a href="https://arxiv.org/abs/2209.05705">Preprint</a></li>
                <li><i class="fab fa-github"></i> <a href="https://github.com/CU-UQ/BF-Boosted-Quadrature-Sampling">Code</a></li>
              </ul>
            </li>

            <li>
              N. Cheng, <u>O. A. Malik</u>, S. De, S. Becker, A. Doostan.
              <i>Bi-fidelity variational auto-encoder for uncertainty quantification</i>.
              <b>Computer Methods in Applied Mechanics and Engineering</b> 421, 2024.
              <ul class="horizontal"> 
                <li><i class="fas fa-file-alt"></i> <a href="https://doi.org/10.1016/j.cma.2024.116793">Paper</a></li>
                <li><i class="ai ai-arxiv ai-1x"></i> <a href="https://arxiv.org/abs/2305.16530">Preprint</a></li>
                <li><i class="fab fa-github"></i> <a href="https://github.com/CU-UQ/Bi-fidelity-VAE">Code</a></li>
              </ul>
            </li>

            <li>
              V. Bharadwaj, <u>O. A. Malik</u>, R. Murray, L. Grigori, A. Bulu√ß, J. Demmel.
              <i>Fast exact leverage score sampling from Khatri-Rao products with applications to tensor decomposition</i>.
              <b>Advances in Neural Information Processing Systems (NeurIPS)</b>, 2023.
              <ul class="horizontal"> 
                <li><i class="fas fa-file-alt"></i> <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/959f70ee50044bed305e48e3484005a7-Abstract-Conference.html">Paper</a></li>
                <li><i class="ai ai-arxiv ai-1x"></i> <a href="https://arxiv.org/abs/2301.12584">Preprint</a></li>
                <li><i class="fab fa-github"></i> <a href="https://github.com/vbharadwaj-bk/fast_tensor_leverage">Code</a></li>
              </ul>
            </li>

            <li>
              R. Border, <u>O. A. Malik</u>.
              <i>rBahadur: efficient simulation of structured high-dimensional genotype data with applications to assortative mating</i>.
              <b>BMC Bioinformatics</b> 24, 314, 2023.
              <ul class="horizontal"> 
                <li><i class="fas fa-file-alt"></i> <a href="https://doi.org/10.1186/s12859-023-05442-6">Paper</a></li>
                <li><i class="ai ai-arxiv ai-1x"></i> <a href="https://doi.org/10.1101/2022.10.13.512132">Preprint</a></li>
                <li><i class="fab fa-github"></i> <a href="https://github.com/rborder/rBahadur">Code</a></li>
              </ul>
            </li>

            <li>
              <u>O. A. Malik</u>.
              <i>More efficient sampling for tensor decomposition with worst-case guarantees</i>. 
              <b>International Conference on Machine Learning (ICML)</b>, PMLR 162, pp. 14887-14917, 2022.
              <ul class="horizontal"> 
                <li><i class="fas fa-file-alt"></i> <a href="https://proceedings.mlr.press/v162/malik22a.html">Paper</a></li>
                <li><i class="ai ai-arxiv ai-1x"></i> <a href="https://arxiv.org/abs/2110.07631">Preprint</a></li>
                <li><i class="fab fa-github"></i> <a href="https://github.com/OsmanMalik/TD-ALS-ES">Code</a></li>
                <li><i class="fa-solid fa-person-chalkboard"></i> <a href="https://slideslive.com/38984000">Talk</a></li>
              </ul>
            </li>

            <li>
              <u>O. A. Malik</u>, H. Ushijima-Mwesigwa, A. Roy, A. Mandal, I. Ghosh.
              <i>Binary matrix factorization on special purpose hardware</i>. 
              <b>PLOS ONE</b> 16(12): e0261250, 2021.
              <ul class="horizontal"> 
                <li><i class="fas fa-file-alt"></i> <a href="https://doi.org/10.1371/journal.pone.0261250">Paper</a></li>
                <li><i class="ai ai-arxiv ai-1x"></i> <a href="https://arxiv.org/abs/2010.08693">Preprint</a></li>
              </ul>
            </li>

            <li>
              <u>O. A. Malik</u>, S. Becker.
              <i>A sampling-based method for tensor ring decomposition</i>. 
              <b>International Conference on Machine Learning (ICML)</b>, PMLR 139, pp. 7400-7411, 2021.
              <ul class="horizontal"> 
                <li><i class="fas fa-file-alt"></i> <a href="http://proceedings.mlr.press/v139/malik21b.html">Paper</a></li>
                <li><i class="ai ai-arxiv ai-1x"></i> <a href="https://arxiv.org/abs/2010.08581">Preprint</a></li>
                <li><i class="fab fa-github"></i> <a href="https://github.com/OsmanMalik/tr-als-sampled">Code</a></li>
                <li><i class="fa-solid fa-person-chalkboard"></i> <a href="https://icml.cc/virtual/2021/poster/8447">Talk</a></li>
              </ul>
            </li>

            <li>
              <u>O. A. Malik</u>, S. Ubaru, L. Horesh, M. E. Kilmer, H. Avron.
              <i>Dynamic graph convolutional networks using the tensor M-product</i>. 
              <b>SIAM International Conference on Data Mining (SDM)</b>, pp. 729-737, 2021.
              <ul class="horizontal"> 
                <li><i class="fas fa-file-alt"></i> <a href="https://doi.org/10.1137/1.9781611976700.82">Paper</a></li>
                <li><i class="ai ai-arxiv ai-1x"></i> <a href="https://arxiv.org/abs/1910.07643">Preprint</a></li>
                <li><i class="fab fa-github"></i> <a href="https://github.com/IBM/TM-GCN">Code</a></li>
              </ul>
            </li>

            <li>
              <u>O. A. Malik</u>, S. Becker. 
              <i>Randomization of approximate bilinear computation for matrix multiplication</i>. 
              <b>International Journal of Computer Mathematics: Computer Systems Theory</b> 6, issue 1, pp. 54-93, 2021.
              <ul class="horizontal"> 
                <li><i class="fas fa-file-alt"></i> <a href="https://doi.org/10.1080/23799927.2020.1861104">Paper</a></li>
                <li><i class="ai ai-arxiv ai-1x"></i> <a href="https://arxiv.org/abs/1905.07439">Preprint</a></li>
                <li><i class="fab fa-github"></i> <a href="https://github.com/OsmanMalik/random-approximate-matrix-multiplication">Code</a></li>
              </ul>
            </li>

            <li>
              <u>O. A. Malik</u>, S. Becker. 
              <i>Fast randomized matrix and tensor interpolative decomposition using CountSketch</i>. 
              <b>Advances in Computational Mathematics</b> 46, article number 76, 2020.
              <ul class="horizontal"> 
                <li><i class="fas fa-file-alt"></i> <a href="https://doi.org/10.1007/s10444-020-09816-9">Paper</a> (<a href="https://rdcu.be/b9eFU">view on SharedIt</a>)</li> 
                <li><i class="ai ai-arxiv ai-1x"></i> <a href="https://arxiv.org/abs/1901.10559">Preprint</a></li>
                <li><i class="fab fa-github"></i> <a href="https://github.com/OsmanMalik/countsketch-matrix-tensor-id">Code</a></li>
              </ul>
            </li>

            <li>
              <u>O. A. Malik</u>, S. Becker.
              <i>Guarantees for the Kronecker fast Johnson‚ÄìLindenstrauss transform using a coherence and sampling argument</i>.
              <b>Linear Algebra and its Applications</b> 602, pp. 120‚Äì137, 2020.
              <ul class="horizontal"> 
                <li><i class="fas fa-file-alt"></i> <a href="https://doi.org/10.1016/j.laa.2020.05.004">Paper</a></li>
                <li><i class="ai ai-arxiv ai-1x"></i> <a href="https://arxiv.org/abs/1911.08424">Preprint</a></li>
                <li><i class="fab fa-github"></i> <a href="https://github.com/OsmanMalik/kronecker-sketching">Code</a></li>
              </ul>
            </li>

            <li>
              <u>O. A. Malik</u>, S. Becker. 
              <i>Low-rank Tucker decomposition of large tensors using TensorSketch</i>. 
              <b>Advances in Neural Information Processing Systems (NeurIPS)</b>, pp. 10096-10106, 2018.
              <ul class="horizontal"> 
                <li><i class="fas fa-file-alt"></i> <a href="http://papers.nips.cc/paper/8213-low-rank-tucker-decomposition-of-large-tensors-using-tensorsketch">Paper</a></li>
                <li><i class="fab fa-github"></i> <a href="https://github.com/OsmanMalik/tucker-tensorsketch">Code</a></li>
              </ul>
            </li>
          </ul>

          <h5>
            Workshop Papers
          </h5>
          <ul class="loose">

            <li>
              <u>O. A. Malik</u>, V. V. Narumanchi, S. Becker, T. W. Murray.
              <i>Superresolution photoacoustic tomography using random speckle illumination and second order moments</i>. 
              <b>IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)</b>, pp. 141-145, 2021.
              <ul class="horizontal"> 
                <li><i class="fas fa-file-alt"></i> <a href="https://doi.org/10.1109/WASPAA52581.2021.9632758">Paper</a></li>
                <li><i class="ai ai-arxiv ai-1x"></i> <a href="https://arxiv.org/abs/2105.03809">Preprint</a></li>
                <li><i class="fab fa-github"></i> <a href="https://github.com/OsmanMalik/SR-PAT-WASPAA-2021">Code</a></li>
              </ul>
            </li>

            <li>
              <u>O. A. Malik</u>, S. Ubaru, L. Horesh, M. E. Kilmer, H. Avron. 
              <i>Tensor graph neural networks for learning on time varying graphs</i>. 
              <b>NeurIPS Workshop on Graph Representation Learning</b>, 2019.
              <ul class="horizontal"> 
                <li><i class="fas fa-file-alt"></i> <a href="https://grlearning.github.io/papers/55.pdf">Paper</a></li>
                <li><i class="fab fa-github"></i> <a href="https://github.com/IBM/TM-GCN">Code</a></li>
              </ul>
            </li>
          </ul>

          <h5>
            Technical Reports
          </h5>
          <ul class="loose">

            <li>
              R. Murray, J. Demmel, M. W. Mahoney, N. B. Erichson, M. Melnichenko, <u>O. A. Malik</u>, L. Grigori, P. Luszczek, M. Derezinski, M. E. Lopes, T. Liang, H. Luo, J. Dongarra.
              <i>Randomized numerical linear algebra: A perspective on the field with an eye to software</i>. 
              Technical Report No. UCB/EECS-2023-19, EECS Department, University of California, Berkeley, 2023.
              <ul class="horizontal"> 
                <li><i class="fas fa-file-alt"></i> <a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2023/EECS-2023-19.html">Report</a></li>
                <li><i class="ai ai-arxiv ai-1x"></i> <a href="https://arxiv.org/abs/2302.11474">Preprint</a></li>
                <li><i class="fab fa-github"></i> <a href="https://github.com/BallisticLA">Code</a></li>
              </ul>
            </li>

          </ul>


          <h5>
            Patents
          </h5>
          <ul class="loose">

            <li>
              <u>O. A. Malik</u>, H. Ushijima, A. Mandal, I. Ghosh, A. Roy.
              <i>Data clustering</i>. 
              US Patent Number: 11,537,637.
              Date of Patent: 27 December 2022.
              <ul class="horizontal"> 
                <li><i class="fas fa-file-alt"></i> <a href="https://patents.google.com/patent/US11537637B2/en">Patent</a></li>
              </ul>
            </li>

            <li>
              L. Horesh, <u>O. A. Malik</u>, S. Ubaru, M. E. Kilmer, H. Avron.
              <i>Tensor-based predictions from analysis of time-varying graphs</i>. 
              US Patent Number: 11,386,507.
              Date of Patent: 12 July 2022.
              <ul class="horizontal"> 
                <li><i class="fas fa-file-alt"></i> <a href="https://patents.google.com/patent/US11386507B2/en">Patent</a></li>
              </ul>
            </li>

          </ul>
        </div>
      </div>
    </div>

  <!-- Footer -->
  <div class="container-fluid">
    <div class="row d-flex justify-content-center" style="margin-top:40px;">
      <div class="col-md-2" style="background:gray">
      </div>
      <div class="col-md-8" style="background:gray">
        <br>
      </div>
      <div class="col-md-2" style="background:gray">
      </div>
    </div>
  </div>
    
  </body>
</html>
